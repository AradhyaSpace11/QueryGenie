{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Information:\n",
      "Sheldon's Formula:\n",
      "Slavery = profit\n",
      "devised by sheldon periperi\n",
      "\n",
      "Response: Sheldon Periperi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import tempfile\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "API_KEY = '",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Initialize the model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Clear the existing Chroma database\n",
    "if os.path.exists(\"chroma_db\"):\n",
    "    shutil.rmtree(\"chroma_db\", ignore_errors=True)\n",
    "\n",
    "# Load the text file\n",
    "loader = TextLoader('text.txt')  # Replace with your file path\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Use embeddings designed for semantic similarity\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Use a temporary directory for Chroma database\n",
    "persist_directory = tempfile.mkdtemp()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# Example query\n",
    "query = input(\"Query:\")  # Replace with your question\n",
    "\n",
    "# Retrieve relevant documents\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print only the most relevant documents\n",
    "print(\"Relevant Information:\")\n",
    "for doc in relevant_docs:\n",
    "    print(doc.page_content +\"\\n\")\n",
    "\n",
    "# Start a chat session\n",
    "chat = model.start_chat()\n",
    "\n",
    "rag_sysin = \"you simply answer questions by using knowledge from a data store. this is your data:\"\n",
    "\n",
    "# Prompt the user for a question\n",
    "user_question = rag_sysin + doc.page_content + \"and here's your query\" + query \n",
    "\n",
    "# Send the user's question to the model\n",
    "response = chat.send_message(user_question)\n",
    "\n",
    "# Print the model's response\n",
    "print(\"Response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import tempfile\n",
    "from PyPDF2 import PdfReader  # Library for reading PDFs\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "API_KEY = '",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Initialize the model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Load the PDF file\n",
    "pdf_path = 'formulas1.pdf'  # Replace with your PDF file path\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(\"Error: PDF file not found!\")\n",
    "    exit(1)\n",
    "\n",
    "# Extract text from the PDF\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Split the text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "docs = text_splitter.create_documents([pdf_text])\n",
    "\n",
    "# Use embeddings designed for semantic similarity\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Use a temporary directory for Chroma database\n",
    "persist_directory = tempfile.mkdtemp()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = input(\"Query: \")  # User-provided question\n",
    "\n",
    "# Retrieve relevant documents\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "combined_content = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "# Print relevant information\n",
    "print(\"Relevant Information:\")\n",
    "print(combined_content + \"\\n\")\n",
    "\n",
    "# Start a chat session\n",
    "chat = model.start_chat()\n",
    "\n",
    "# Create a structured prompt\n",
    "user_question = f\"\"\"\n",
    "You are an AI system answering queries based on a data store. \n",
    "Here is the data you should use:\n",
    "{combined_content}\n",
    "\n",
    "Here is the user's query:\n",
    "{query}\n",
    "\n",
    "Please provide a detailed and accurate answer.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Send the user's question to the model\n",
    "    response = chat.send_message(user_question)\n",
    "    print(\"Response:\", response.text)\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "# Clean up temporary directories\n",
    "shutil.rmtree(persist_directory, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
