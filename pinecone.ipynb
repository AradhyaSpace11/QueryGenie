{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -U langchain-community PyPDF2 pinecone-client sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai migrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! PDF data has been added to Pinecone.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Initialize Pinecone with your API key\n",
    "pc = Pinecone(\n",
    "    api_key=\"pcsk_327fZT_9n2i2FHdK1rXvfFN2RK2i4Z7edicDFE7sSFmyE1bVuGgjjZfAUXUtncrqyUk1Am\"  # Replace with your Pinecone API key\n",
    ")\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"formulae-index\"\n",
    "\n",
    "# Check if the index exists; if not, create it\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,  # Ensure this matches your embedding model output dimension\n",
    "        metric=\"cosine\",  # Metric for similarity search\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")  # Adjust region based on your setup\n",
    "    )\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Load and process the PDF\n",
    "pdf_path = \"medicalformulae.pdf\"  # Replace with your PDF file path\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Split the text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n",
    "docs = text_splitter.create_documents([pdf_text])\n",
    "\n",
    "# Embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Generate embeddings and upsert into Pinecone\n",
    "vectors = []\n",
    "for i, doc in enumerate(docs):\n",
    "    embedding = embeddings.embed_query(doc.page_content)\n",
    "    vectors.append({\n",
    "        \"id\": f\"doc-{i}\",\n",
    "        \"values\": embedding,\n",
    "        \"metadata\": {\"content\": doc.page_content}\n",
    "    })\n",
    "\n",
    "index.upsert(vectors)\n",
    "print(\"Training complete! PDF data has been added to Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your questions (type 'exit' to quit):\n",
      "Relevant Information:\n",
      "\\] \n",
      "Where:  \n",
      "\\begin{itemize}  \n",
      "    \\item \\( \\text{DBP} \\) = Diastolic Blood Pressure  \n",
      "    \\item \\( \\text{SBP} \\) = Systolic Blood Pressure  \n",
      "\\end{itemize}  \n",
      " \n",
      "\\subsection*{3. Cardiac Output (CO)}\n",
      "--------------------------------------------------\n",
      "\\[ \n",
      "\\text{BMI} = \\frac{ \\text{Weight (kg)}}{ \\text{Height (m)}^2}  \n",
      "\\] \n",
      " \n",
      "\\subsection*{2. Mean Arterial Pressure (MAP)}  \n",
      "\\[ \n",
      "\\text{MAP} = \\text{DBP} + \\frac{ \\text{SBP} - \\text{DBP}}{3}  \n",
      "\\]\n",
      "--------------------------------------------------\n",
      "\\[ \n",
      "\\text{CO} = \\text{SV} \\times \\text{HR}  \n",
      "\\] \n",
      "Where:  \n",
      "\\begin{itemize}  \n",
      "    \\item \\( \\text{SV} \\) = Stroke Volume  \n",
      "    \\item \\( \\text{HR} \\) = Heart Rate  \n",
      "\\end{itemize}\n",
      "--------------------------------------------------\n",
      "\\item \\( \\text{Patm} \\) = Atmospheric Pressure  \n",
      "    \\item \\( \\text{PH}_2 \\text{O} \\) = Water Vapor Pressure  \n",
      "    \\item \\( \\text{PaCO}_2 \\) = Partial Pr essure of Arterial CO \\(_2\\)\n",
      "--------------------------------------------------\n",
      "Exiting. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(\n",
    "    api_key=\"pcsk_327fZT_9n2i2FHdK1rXvfFN2RK2i4Z7edicDFE7sSFmyE1bVuGgjjZfAUXUtncrqyUk1Am\"  # Replace with your Pinecone API key\n",
    ")\n",
    "\n",
    "# Connect to the existing index\n",
    "index_name = \"formulae-index\"  # Ensure this matches the trained index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Inference loop\n",
    "print(\"Ask your questions (type 'exit' to quit):\")\n",
    "while True:\n",
    "    # Take user input\n",
    "    user_query = input(\"Your question: \").strip()\n",
    "    \n",
    "    # Exit condition\n",
    "    if user_query.lower() == \"exit\":\n",
    "        print(\"Exiting. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embeddings.embed_query(user_query)\n",
    "    \n",
    "    # Query the Pinecone index\n",
    "    response = index.query(vector=query_embedding, top_k=4, include_metadata=True)\n",
    "    \n",
    "    # Check if matches are found\n",
    "    if not response.matches:\n",
    "        print(\"No relevant information found.\")\n",
    "    else:\n",
    "        print(\"Relevant Information:\")\n",
    "        for match in response.matches:\n",
    "            print(match['metadata']['content'])\n",
    "            print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    api_key=\"pcsk_327fZT_9n2i2FHdK1rXvfFN2RK2i4Z7edicDFE7sSFmyE1bVuGgjjZfAUXUtncrqyUk1Am\"  # Replace with your Pinecone API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your questions (type 'exit' to quit):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Information:\n",
      "--------------------------------------------------\n",
      "Gemini Response:\n",
      "The Cockcroft-Gault formula is used to estimate creatinine clearance (CrCl).  For males, the formula is:\n",
      "\n",
      "CrCl = [(140 - Age) × Weight (kg)] / [Serum Creatinine (mg/dL) × 72]\n",
      "\n",
      "--------------------------------------------------\n",
      "Relevant Information:\n",
      "--------------------------------------------------\n",
      "Gemini Response:\n",
      "```sql\n",
      "-- Assuming a table named 'patient_data' with the following columns:\n",
      "-- Age (INT), Weight_kg (FLOAT), Serum_Creatinine_mg_dL (FLOAT), Sex (VARCHAR), Race (VARCHAR)\n",
      "\n",
      "SELECT\n",
      "    Age,\n",
      "    Weight_kg,\n",
      "    Serum_Creatinine_mg_dL,\n",
      "    CASE\n",
      "        WHEN Sex = 'Male' THEN (140 - Age) * Weight_kg / (Serum_Creatinine_mg_dL * 72)\n",
      "        ELSE (140 - Age) * Weight_kg / (Serum_Creatinine_mg_dL * 72) * 0.85  -- Assuming 85% of male value for females.  A more accurate calculation would require a separate formula for females as shown in the provided text.\n",
      "    END as Cockcroft_Gault_CrCl\n",
      "FROM\n",
      "    patient_data;\n",
      "\n",
      "```\n",
      "\n",
      "**Note:** The Cockcroft-Gault formula provided doesn't explicitly differentiate between males and females.  The provided text mentions a separate formula (MDRD) for calculating GFR that incorporates sex and race.  The SQL query above provides a *crude approximation* for females using 85% of the male value.  For a more accurate calculation,  the MDRD formula (also provided in the text) should be implemented, which would require additional columns in the table to store necessary variables (Serum Creatinine, Age, Sex, and Race).  Additionally, a more robust solution would involve handling potential null values and division by zero errors.\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Initialize Pinecone\n",
    "pc = Pinecone(\n",
    "    api_key=\"pcsk_327fZT_9n2i2FHdK1rXvfFN2RK2i4Z7edicDFE7sSFmyE1bVuGgjjZfAUXUtncrqyUk1Am\"  # Replace with your Pinecone API key\n",
    ")\n",
    "\n",
    "# Connect to the existing index\n",
    "index_name = \"formulae-index\"  # Ensure this matches the trained index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "# Configure Google Gemini API\n",
    "API_KEY = \"AIzaSyAZsRTDVpsPRhHpezqaIc2ZvanreBv0Xx4\"\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Initialize Gemini Model\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Function to query Google Gemini\n",
    "def query_gemini(query, relevant_info):\n",
    "    try:\n",
    "        chat = gemini_model.start_chat()\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI system answering queries based on a data store. \n",
    "        Here is the data you should use:\n",
    "        {relevant_info}\n",
    "\n",
    "        Here is the user's query:\n",
    "        {query}\n",
    "\n",
    "        Now you are supposed to take this data into context and write SQL queries if asked to do so, if not asked, reply without sql queries\n",
    "        \"\"\"\n",
    "        response = chat.send_message(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Gemini: {e}\")\n",
    "        return None\n",
    "\n",
    "# Inference loop\n",
    "print(\"Ask your questions (type 'exit' to quit):\")\n",
    "while True:\n",
    "    # Take user input\n",
    "    user_query = input(\"Your question: \").strip()\n",
    "    \n",
    "    # Exit condition\n",
    "    if user_query.lower() == \"exit\":\n",
    "        print(\"Exiting. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embeddings.embed_query(user_query)\n",
    "    \n",
    "    # Query the Pinecone index\n",
    "    response = index.query(vector=query_embedding, top_k=4, include_metadata=True)\n",
    "    \n",
    "    # Check if matches are found\n",
    "    if not response.matches:\n",
    "        print(\"No relevant information found.\")\n",
    "    else:\n",
    "        # Combine relevant information\n",
    "        relevant_info = \"\\n\".join([match['metadata']['content'] for match in response.matches])\n",
    "        print(\"Relevant Information:\")\n",
    "        #print(relevant_info)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Query Gemini with the relevant info\n",
    "        gemini_response = query_gemini(user_query, relevant_info)\n",
    "        if gemini_response:\n",
    "            print(\"Gemini Response:\")\n",
    "            print(gemini_response)\n",
    "            print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
